# üöÄ AplicacionDeSpeedrunConAI

<img width="950" height="537" alt="Screenshot 2025-07-26 194201" src="https://github.com/user-attachments/assets/d5b357c9-9f42-4135-92ad-3ee9729bc896" />

[![Demo del proyecto](https://img.youtube.com/vi/BMqF3_rKCw8/0.jpg)](https://www.youtube.com/watch?v=BMqF3_rKCw8)


Proyecto de speedrun automatizado con IA integrada en Godot Engine usando aprendizaje por refuerzo (RL).

Aplicaci√≥n de aprendizaje por refuerzo en un entorno de videojuego desarrollado para la simulaci√≥n de estrategias de speedrun con un agente inteligente
Es un investigaci√≥n que propone el desarrollo de un entorno de videojuego plataformero en Godot Engine 4.3, dise√±ado para entrenar un agente de inteligencia artificial (IA) mediante aprendizaje por refuerzo (RL) con el fin de optimizar estrategias de speedrun (completar el nivel en el menor tiempo posible sin recibir danio). El proyecto busca demostrar la eficacia de algoritmos como PPO (Proximal Policy Optimization) en la automatizaci√≥n de rutas eficientes, adaptaci√≥n a obst√°culos din√°micos, evitar danio y mejora iterativa del rendimiento. La necesidad de fomentar el aprendizaje pr√°ctico de la inteligencia artificial y el desarrollo de videojuegos como herramientas educativas. Al dise√±ar un entorno accesible donde una IA aprenda a completar un juego del genero plataformero, se busca demostrar el potencial de estas tecnolog√≠as para motivar la ense√±anza de la programaci√≥n. Desarrollar un entorno interactivo de videojuego plataformero en Godot Engine y entrenar un agente de inteligencia artificial mediante aprendizaje por refuerzo (RL) utilizando algoritmos como PPO para optimizar estrategias de speedrun, demostrando su capacidad para: Automatizar rutas eficientes en tiempo real. Adaptarse din√°micamente a obst√°culos y mec√°nicas complejas (ej: saltos precisos, dashes). Mejorar iterativamente su rendimiento mediante recompensas basadas en tiempo y eficiencia de movimientos. Objetivos Espec√≠ficos Dise√±ar y desarrollar un videojuego plataformero 2D en Godot Engine Implementar mec√°nicas clave para speedruns (saltos, dashes, plataformas m√≥viles). Programar f√≠sicas personalizadas (gravedad, colisiones) y niveles con obst√°culos din√°micos. Integrar un sistema de comunicaci√≥n entre Godot y el agente de RL Exponer variables estructuradas (posici√≥n, velocidad, estado del personaje) mediante una API. Establecer un protocolo para enviar acciones del agente al juego (ej: movimientos, saltos). Implementar y entrenar un agente de RL, PPO Dise√±ar una funci√≥n de recompensa que optimice el tiempo de completado (reward = - tiempo). Comparar el rendimiento del agente contra estrategias baselines (jugador humano, aleatorio). Evaluar la adaptabilidad del agente en escenarios no vistos Probar su desempe√±o en niveles con disposiciones de plataformas distintas a las de entrenamiento. Analizar su respuesta ante obst√°culos din√°micos (ej: enemigos con patrones cambiantes). Cuantificar m√©tricas de √©xito (tiempo promedio, tasa de victoria, eficiencia de movimientos).

Objetivos Espec√≠ficos
Dise√±ar y desarrollar un videojuego plataformero 2D en Godot Engine
Implementar mec√°nicas clave para speedruns (saltos, dashes, plataformas m√≥viles).

Programar f√≠sicas personalizadas (gravedad, colisiones) y niveles con obst√°culos din√°micos.
Integrar un sistema de comunicaci√≥n entre Godot y el agente de RL
Exponer variables estructuradas (posici√≥n, velocidad, estado del personaje) mediante una
API.
Establecer un protocolo para enviar acciones del agente al juego (ej: movimientos, saltos).
Implementar y entrenar un agente de RL (PPO)
Dise√±ar una funci√≥n de recompensa que optimice el tiempo de completado (reward = -
tiempo).
Comparar el rendimiento del agente contra estrategias baselines (jugador humano,
aleatorio).
Evaluar la adaptabilidad del agente en escenarios no vistos
Probar su desempe√±o en niveles con disposiciones de plataformas distintas a las de
entrenamiento.
Analizar su respuesta ante obst√°culos din√°micos (ej: enemigos con patrones cambiantes).
Documentar el proceso y resultados
Cuantificar m√©tricas de √©xito (tiempo promedio, tasa de victoria, eficiencia de
movimientos).
Generar material educativo que relacione desarrollo de videojuegos con RL para fines
acad√©micos.

OBJETIVOS
Objetivo General
Desarrollar un sistema aut√≥nomo que, mediante la integraci√≥n de un entorno de videojuego en Godot Engine y un agente basado en aprendizaje por refuerzo (PPO), optimice estrategias de speedrun y demuestre capacidades de generalizaci√≥n ante entornos no vistos.
Objetivos Espec√≠ficos
Dise√±ar un entorno plataformero 2D con mec√°nicas reproducibles para el entrenamiento del agente.
Implementar una comunicaci√≥n bidireccional entre Godot y Python mediante sockets TCP/IP.
Entrenar un agente PPO con Stable Baselines3 para optimizar la velocidad de completado de los niveles.
Evaluar el rendimiento del agente frente a jugadores humanos y agentes aleatorios.
Documentar el proceso t√©cnico y metodol√≥gico para su replicaci√≥n en entornos educativos.

METODOLOGIA
La metodolog√≠a combina investigaci√≥n te√≥rica y desarrollo t√©cnico experimental, dividida en fases.
Fase te√≥rica
Revisi√≥n bibliogr√°fica de RL aplicado a videojuegos (DQN en Atari, PPO en Unity ML-Agents).
Estudio de t√©cnicas de speedrun en juegos cl√°sicos (Super Mario Bros, Celeste) para identificar mec√°nicas clave (saltos en pared, cadenas de dash).
An√°lisis de funciones de recompensa utilizadas en optimizaci√≥n temporal (reward shaping, discount factors).
Fase t√©cnica
Selecci√≥n de herramientas:
Motor de juego: Godot Engine 4.3 por su sistema modular, f√≠sicas personalizables y soporte para GDScript.
Framework de RL: Stable Baselines3 (PPO), equilibrando facilidad de integraci√≥n y rendimiento.
Protocolo de comunicaci√≥n: Socket TCP/IP, con intercambio de variables (posici√≥n, velocidad, estado del dash, datos de plataformas m√≥viles).
M√©tricas de evaluaci√≥n:
Tiempo promedio por nivel.
Eficiencia de movimientos (acciones redundantes penalizadas).
Tasa de generalizaci√≥n (% de √©xito en niveles no vistos).

## üîß Instalaci√≥n y Configuraci√≥n

### Prerrequisitos
| Herramienta | Versi√≥n m√≠nima | Enlace de descarga |
|-------------|----------------|-------------------|
| Godot Engine | 4.3 | [Descargar](https://godotengine.org/download) |
| Python | 3.10 | [Instalador](https://www.python.org/downloads/) |
| Git | 2.30+ | [Instalador](https://git-scm.com/downloads) |
| VSCode (Opcional) | 1.75+ | [Descargar](https://code.visualstudio.com/) |

### üîÑ Configuraci√≥n del entorno virtual de Python
```bash
# Clonar repositorio
git clone https://github.com/MathSantill/AplicacionDeSpeedrunConAI.git
cd AplicacionDeSpeedrunConAI

# Crear y activar entorno virtual (Windows)
python -m venv .venv
.venv\Scripts\activate

# Crear y activar entorno virtual (Linux/macOS)
python -m venv .venv
source .venv/bin/activate

Se recomienda estructurar los datos en formato JSON para facilidad de parsing y flexibilidad.

GitHub + GitHub Actions: para control de versiones, integraci√≥n continua y automatizaci√≥n del despliegue.
```

```bash
Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned
.\rl\Scripts\Activate.ps1
```

```bash
py stable_baselines3_example.py --speedup=4 --timesteps=300000
```

### Arquitectura Implementada
Visi√≥n General
Estamos implementando una arquitectura cliente-servidor con separaci√≥n estricta de responsabilidades, dise√±ada para:

Aislar el motor del juego (Godot) de la l√≥gica de IA (Python)

Permitir entrenamiento offline de modelos RL

Facilitar la integraci√≥n continua y despliegue

Mantener alta performance en tiempo real

Capas de la Arquitectura (en orden de implementaci√≥n)
1. Capa de Presentaci√≥n (Godot Engine)
Aspecto	Detalle
Responsabilidad	Renderizado gr√°fico, interfaz de usuario y f√≠sica del juego
Tecnolog√≠as	Godot Engine 4.3, GDScript (81.3%), C# (9.9%)
Ubicaci√≥n	Sprites/, Levels/, Scripts/Player/
Estado:	 Completado (100%)

2. Capa de Control de Juego
Aspecto	Detalle
Responsabilidad	Gesti√≥n de estados del juego, mec√°nicas y reglas
Tecnolog√≠as	GDScript, sistema de nodos de Godot
Ubicaci√≥n	Scripts/Game/
Componentes clave	game_manager.gd, level_loader.gd
Estado: Completado (100%)

3. Capa de Comunicaci√≥n
Aspecto	Detalle
Responsabilidad	Intercambio de datos entre juego y servidor de IA
Tecnolog√≠as	API REST (FastAPI), JSON over HTTP
Implementaci√≥n	Godot: Scripts/AIController/agent.gd, Python: api.py
Protocolo	HTTP POST con estado del juego ‚Üí Respuesta JSON con acci√≥n
Estado: En desarrollo (85%)

4. Capa de L√≥gica de IA
Aspecto	Detalle
Responsabilidad	Procesamiento de estados y generaci√≥n de acciones √≥ptimas
Tecnolog√≠as	Python 3.10+, Stable-Baselines3 (PPO/DQN), PyTorch
Ubicaci√≥n	api.py, stable_baselines3_example.py
Estado: En desarrollo (70%)

5. Capa de Persistencia
Aspecto	Detalle
Responsabilidad	Almacenamiento de modelos entrenados y datos de sesiones
Tecnolog√≠as	Sistema de archivos local, formato .zip para modelos
Implementaci√≥n	Directorio models/, training_logs/
Estado: Pendiente (0%)

6. Capa de Entrenamiento (Offline)
Aspecto	Detalle
Responsabilidad	Entrenamiento y optimizaci√≥n de modelos RL
Tecnolog√≠as	Python scripts, GitHub Actions (CI/CD)
Ubicaci√≥n	.github/workflows/train.yml
Estado: Pendiente (30%)
Flujo Completo de Datos

Ciclo de Vida de una Acci√≥n
Captura: Godot recolecta estado del juego (60 FPS)
Preparaci√≥n: Datos se estructuran en JSON
Transmisi√≥n: HTTP POST a localhost:5000/action

Procesamiento:
Servidor recibe estado
Modelo RL calcula mejor acci√≥n

Respuesta:
Acci√≥n serializada en JSON
Enviada de vuelta a Godot
Ejecuci√≥n: Godot aplica acci√≥n en pr√≥ximo frame
Retroalimentaci√≥n: Resultado usado para pr√≥ximo ciclo
Evoluci√≥n de la Implementaci√≥n
Fase Inicial (Completada)
Configuraci√≥n de Godot Engine
Dise√±o b√°sico de niveles
Movimiento b√°sico del personaje
Sistema de colisiones
Fase Actual (Implementando)
Integraci√≥n API REST
Comunicaci√≥n Godot-Python
Modelo RL b√°sico (PPO)
Sistema de acciones parametrizadas
Gesti√≥n de estados del juego
Pr√≥xima Fase
Entrenamiento avanzado con recompensas
Optimizaci√≥n de comunicaci√≥n
Sistema de persistencia para modelos
Integraci√≥n CI/CD con GitHub Actions
Sistema de logging y m√©tricas
Desarrollo paralelo de componentes
Actualizaciones independientes
Escalabilidad para nuevos algoritmos RL
Portabilidad entre proyectos
Monitoreo granular del rendimiento
